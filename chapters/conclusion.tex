\paragraph{}In this dissertation, three parameter optimization algorithms for \ac{SLAM} systems were implemented, namely Grid Search, Random Search, and Simulated Annealing. These optimization algorithms have five components: dataset definition, \ac{SLAM} algorithm, tuning algorithm and parameter selection, and metric weights. The parameter selection requires a search space to be delimited. For Grid and Random Search, this mean defining upper and lower bounds, as well as a step size, for each parameter. For Simulated Annealing, additional settings related to perturbation functions and reannealing must be specified. Assigning weights to each metric (in this case, only the \ac{APE} and \ac{RPE} were considered) enables the research to optimize the selected SLAM algorithm with respect to a specific metric. All relevant components can be specified through an external configuration file.

%Attributing weights to each metric(in this case, only the \ac{APE} and \ac{RPE} were considered) allows the tuner to optimize the chosen \ac{SLAM} algorithm for one of the metrics. Through an external configuration file, the tuner can specify all the components just mentioned.

\paragraph{}For testing the implementations, the BotanicGarden dataset was used, specifically the 1006\_03 sequence, and the chosen state-of-the-art \ac{SLAM} solutions were Faster-LIO and Fast-LIVO2. As for metrics, both Faster-LIO and Fast-LIVO2 were optimized for the \ac{RPE}. A few parameters were chosen for both algorithms, and their upper and lower bounds delimited accordingly. The tuning algorithms algorithms were then run and their performance compared. It was found that Grid and Random Search had a slightly worse performance than the default executions, while Simulated Annealing managed to achieve a 4.1\% lower \ac{RPE} in the case of Faster-LIO, and a 84.69\% lower \ac{RPE} in the case of Fast-LIVO2. Although Grid and Random Search are both baseline methods, their poor performance is partly explained by the fact that \ac{RUSTLE} stores every \ac{SLAM} data on a local database, thereby substantially increasing both disk usage and run time, imposing a practical limit on the granularity of the search space for both Grid and Random Search. Nevertheless, the implemented tuning algorithms are universal (agnostic to the \ac{SLAM} solution they are optimizing) and can be a viable option for increasing the performance of any \ac{SLAM} solution.

%The algorithms were then run on two different test cases. Firstly, I evaluated the performance of all three tuning algorithms as contrasted to its default configuration. It was found that Grid and Random Search had a slightly worse performance that the default executions, while Simulated Annealing managed to achieve a 4.1\% lower \ac{RPE} in the case of faster-lio, and a placeholder\% lower \ac{RPE} in the case of fast-livo2. Although Grid and Random Search are both baseline methods, their poor performance is partly explained by referencing a previously explained \ac{RUSTLE} structural limitation, imposing a practical limit on the granularity of the search space for both Grid and Random Search. Nevertheless, the implemented tuning algorithms are universal(agnostic to the \ac{SLAM} solution they are optimizing) and can be a viable option for increasing the performance of any \ac{SLAM} solution.

%Escrever algo sobre os testes de generalização

\paragraph{}

\section{Future work}

%\paragraph{}I have adapted and implemented three hyperparameter tuning algorithms to \ac{SLAM} optimization. The algorithms show some promise in enhancing \ac{SLAM} performance, but there are still many open questions to answer.

\paragraph{}Three parameter tuning algorithms were adapted and implemented for SLAM optimization. These algorithms demonstrate potential for improving SLAM performance; however, there is still significant room for improvements.

\subsubsection{Tuning Algorithms}

\paragraph{}Section 3.2 proposed using Grid Search, Random Search and Simulated Annealing as the algorithms to fine tune \ac{SLAM}. Due to time constraints, it was not possible to implement other, more efficient algorithms such as Bayesian Optimization or Successive Halving. Future work will involve implementing those, as well to fine tune the already implementated algorithms. Some examples of such improvements are tweaking the halting and reannealing conditions of Simulated Annealing, or adjusting the step sizes of a few parameters in Grid and Random Search for finder exploration.

\paragraph{}Additionally, given the moderate success of Simulated Annealing, future work will involve studying and implementing additional meta-heuristic algorithms, such as Particle Swarm Optimization and Genetic Algorithms.

%I plan to study and implement other meta-heuristic based algorithms, such as Particle Swarm or Genetic algorithms.

\subsubsection{Other \ac{SLAM} Solutions}

%\paragraph{}I explored the application of the implemented tuning strategies on faster-lio and fast-livo2. Theoretically, the tuning process relies on the chosen dataset and not the \ac{SLAM} algorithm. It was therefore assumed the implemented tuning algorithms might work just as well on other \ac{SLAM} solutions. In the future, I plan to use the implemented optimization algorithms on different \ac{SLAM} solutions(e.g ig-lio, lio-sam), and compare the effectiveness of hyperparameter tuning on different \ac{SLAM} solutions.

\paragraph{}The implemented tuning algorithms were applied to Faster-LIO and Fast-LIVO2. In principle, the tuning process depends on the selected dataset rather than the specific \ac{SLAM} algorithm. It was therefore assumed that the implemented optimization algorithms could be equally effective for other \ac{SLAM} solutions. Future work will involve applying these algorithms to alternative \ac{SLAM} frameworks (e.g., IG-LIO, LIO-SAM) and evaluating the relative effectiveness of parameter tuning across different SLAM methods.