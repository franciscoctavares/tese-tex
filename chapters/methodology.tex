\paragraph{}This chapter will explain the methodology and requirements for the \ac{SLAM} tuning module, developed for \ac{RUSTLE}. For each implemented tuning algorithm, a high level overview of its architecture is provided. Test settings, including test algorithms and dataset choices, are also justified.

\section{\acs{RUSTLE}}

\begin{figure}[h]
    \centering
    \includegraphics[page=2,width=\linewidth]{images/rustle_diagram.pdf}
    \caption{\ac{RUSTLE} diagram}
\end{figure}

\paragraph{}\ac{RUSTLE} is a command line application, written in Rust, which is designed to simplify the evaluation of SLAM algorithms in mobile robotics.
Its main objective is to provide a simple, stream-lined and reproducible way to run and compare SLAM algorithms. It tracks not only trajectory accuracy(APE or RPE), but also runtime, CPU load and memory usage, offering a more complete assessment of the algorithm's performance.

\paragraph{}At its core, RUSTLE takes three main inputs: a dataset in rosbag format, the SLAM algorithm's parameters in yaml format, and the algorithms themselves as docker images. The reason for using Docker is for reliably reproducing the algorithms across many different platforms and environments.
During execution, the odometry data is streamed into the database(Surrealdb), which, after conclusion, is used to calculate trajectory errors such as the APE and the RPE, using EVO.

\paragraph{}Algorithm executions are run as tests. Each test's configuration is passed as an YAML file, and contains: its name, number of workers, number of iterations, list of algorithms, dataset on which to execute these algorithms and the test type. Additionally, some additional fields might be required, depending on the type of test to be executed.

%% Explicar os vários tipos de testes

\section{Development}

\paragraph{}Development follows an incremental approach, focusing on small incremental features, well thought and tested. Each big feature, such as random search tuning, is divided into smaller, easier to test and debug sub-features. The reason for this is to make it easier to reason about how to implement the feature, as well as, during development, to make it easier to test and debug each sub-feature.

\subsection{Implementation}

\paragraph{}The optimization algorithms that were chosen to be implemented are: Grid Search, Random Search and Simulated Annealing. In section 2, more algorithms were mentioned, specifically Bayesian Optimization, Successive Halving and Hyperband. The reasons for deciding only to implement these three of the six are twofold. Firstly, Grid Search serves as a baseline, exhaustive search method, despite being inefficient for large parameter spaces. Random Search is a natural improvement over Grid Search, finding better configurations faster, particularly under a fixed computational budget~\cite{bergstra2012random}. Finally, Simulated Annealing was selected by being a meta-heuristic and a trajectory based method which is capable of escaping local minima. The reason for choosing only three methods out of the six described in section 2 is mostly based on time constraints. Implementing more than 3 methods, particularly Bayesian Optimization and HyperBand, might prove to be too much of a challenge, considering one has to write the code, but also to run each tuning algorithm for multiple runs, for each chosen \ac{SLAM} solution, all before extracting the results, and discussing them in the present dissertation.

\paragraph{}In addition to the optimization algorithms, it will also be necessary to write code for exporting results of a tuning test, for later result extraction, processing and discussion, as well as code for parsing a YAML settings file, with all necessary information to run the optimization experiment. Finally, some python scripts will be developed to plot the results of the tuning experiments, which will be presented in the next chapter of this dissertation. Below is a high-level diagram of the features I intend to implement.

% diagrama alto-nível das features(feito em powerpoint)

\subsubsection{Simulated Annealing}

\paragraph{}The Simulated Annealing algorithm implementation is identical to the one provided by Stefan Kroboth~\cite{argmin_ref}.

\paragraph{}For floating-point parameters, the used perturbation function samples a normal distribution function and adds the sampled value to the current value of the parameter. Both the mean and the standard deviation of this normal distribution are hyperparameters that can be specified in a YAML configuration file.

\begin{equation}
	\Delta_{float} \sim \mathcal{N}(m, d^2)
\end{equation}

\paragraph{}For integer parameters, a maximum step size is specified for each parameter,  and that step size is multiplied by the current temperature. Then a random integer is generated between the result of that multiplication(see equation~\ref{delta_int}).

\begin{equation}
	\Delta_{int} \in [-t_i * max\_step, t_i * max\_step]
	\label{delta_int}
\end{equation}

\paragraph{}$\Delta_{int}$ is then added to the current value of the parameter, and the value is truncated if it is higher that the parameter's upper bound or lower than its lower bound. Both the upper and lower bounds, as well as the maximum step size for each integer parameter, can be customized used a YAML configuration file.

\paragraph{}During the execution of the algorithm, it is sometimes necessary to reanneal, that is, to reset the temperature to a previous, higher level, to allow the algorithm to escape(or at least try to) a local minima. With that in mind, 3 parameters are necessary:

\begin{itemize}
	\item reanneal\_fixed - the algorithm resets the temperature no matter what after this many iterations  
	\item reanneal\_accepted - the algorithm resets the temperature if no neighbor solution is accepted after this many \textbf{consecutive} iterations
	\item reanneal\_best - the algorithm resets the temperature if no solution better than the incumbent is found after this many \textbf{consecutive} iterations
\end{itemize}

\paragraph{}As for halting conditions, 2 parameters are specified:

\begin{itemize}
	\item stop\_accepted - The algorithm stops its execution if this no neighbor solution is accepted for these many \textbf{consecutive} iterations
	\item stop\_best - the algorithm stops its execution if no solution better than the incumbent is found after these many \textbf{consecutive} iterations
\end{itemize}

\subsubsection{Grid Search}

\paragraph{}The Grid Search implementation considers the parameter space as a multi dimensional tensor, where each dimension corresponds to a different parameter, and has a differing number of possible values. In each iteration, to obtain the current values of the parameters

\begin{figure}[h]
\centering
\begin{algorithm}[H]
\caption{Grid Search}
\begin{algorithmic}[1]
\For{$t = 1, 2, ..., n$}
	\State Obtain the corresponding values of the parameters from the index of the configuration
	\State Evaluate the configuration and extract metrics
	\State If halting conditions are met(time limit or number of configurations), stop the algorithm's execution
\EndFor
\end{algorithmic}
\end{algorithm}
\caption{Grid Search procedure}
\label{bo_algo}
\end{figure}

\paragraph{}The halting conditions can be customized via a YAML configuration file. Similarly, the parameter space can be designed in the following way:

\begin{equation}
	parameter\_name: [first\_value,  step\_size,  number\_of\_values]
	\label{parameter_space_equation}
\end{equation}

\paragraph{}Additionally, the code checks the default configuration and catches most common errors, such as the user passing a String for a parameter that is supposed to be an integer.

\subsubsection{Random Search}

\paragraph{}The Random Search Implementation is similar to Grid Search, except that the index of the configuration to be evaluated is randomly generated, and no configuration is evaluated twice, by way of checking a list of previously evaluated configurations.

\begin{figure}[h]
\centering
\begin{algorithm}[H]
\caption{Random Search}
\begin{algorithmic}[1]
\For{$t = 1, 2, ..., n$}
	\State Generate a random number between in the interval [0, n], and check if the number is on the previously generated numbers list. If it is, keep generating numbers until it isn't.
	\State Add the number to the previously generated numbers list.
	\State Obtain the parameter's current values and update the \ac{SLAM} configuration
	\State Evaluate the configuration and extract metrics
	\If{(elapsed\_time > time\_limit) or (evaluated\_configs > max\_iterations)}
		   		suspend algorithm execution
	\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}
\caption{Random Search procedure}
\label{bo_algo}
\end{figure}

\paragraph{}As in Grid Search, in Random Search, both the parameter space and the halting conditions can be specified in a YAML configuration file.

\paragraph{}What i will be doing: explain the features i will be developing, where my code inserts itself inside of RUSTLE, which optimization strategies will be implemented and why, what tests i will do to test the code and to extract results.

\section{Functional requirements}

\paragraph{}The system must allow users to define all relevant settings for the tuning process using a YAML configuration file. This configuration file will serve as the main interface for specifying the tuning method, SLAM algorithm, and dataset to be used. In addition, it will enable the user to indicate which parameters are to be optimized, with one or more values per parameter. Additionaly, the code must ensure type safety, meaning, for example, that a parameter which is supposed to be a String cannot have a u64 passed as a value. Also, the user must have the option of specifying only the parameters he wants to optimize. 

\paragraph{}For grid and random search tuning methods, the configuration file must support flexible representations of parameter values. Each tunable parameter can be defined as a single value, representing a fixed setting, or as an array containing multiple candidate values to be tested. For numerical parameters(integers and floats), a third specification pattern must be supported: a linearly spaced vector. This vector will be described by a three-element array in the form \textbf{[start, step, number\_of\_elements]}, which the system will interpret to automatically generate a sequence of values. This feature will simplify the definition of evenly spaced search spaces for numerical parameters and ensures consistency across different tuning runs. It also makes it significantly less cumbersome to define large sequences of values.

\paragraph{}Every tuning algorithm has, besides the parameter space, some method specific hyperparameters that control its behavior, such as the budget(grid search) or the cooling factor(SA). Each of these parameters must have a default value, so the user doesn't need to fine tune the tuning algorithm's behavior. As for the budget \textbf{B}, a common hyperparameter used in tuning algorithms, it must be either time based, or iterations based(maximum number of iterations to run).

\paragraph{}For easier development and integration with the overall code structure of RUSTLE, the tuning of an algorithm's hyperparameters is treated as a test. Each configuration is run as a \textbf{simple test}, already defined in the code, changing hyperparameters between iterations. This methodology will allow for greater re-usage of already written code, saving on development time.

\paragraph{}When running a tuning test, each configuration and its metrics(results) must be stored for later processing. The tuning method's hyperparameters must be stored as well, mostly for benchmarking purposes.

\paragraph{}For benchmarking different tuning algorithms, there must be a command as simple as \textbf{tune benchmark -algo xxxxx -dataset xxxxx}, which runs a few preselected tuning algorithms, and displays a few performance metrics.

\paragraph{}Whenever possible, configurations should be run concurrently.

\paragraph{}The code written should be future proof, allowing for easier future integrations of more tuning methods into the software.


%\begin{itemize}
	%\item allow the user to specify which tuning method, algorithm and dataset, and also the parameters to optimize using a yaml configuration file.
	%\item For grid and random search, for any tuned parameters in the configuration file, the general pattern should be either a single value or an array of various values. For numerical parameters(integers or real numbers), a third option must be available: a linearly spaced vector, and that vector is specified through a 3 element array whose elements are [start, step, number\_of\_elements], allowing for the specification of arrays of  n values, without the cumbersomeness of manually specifying all the values.
	%\item Other settings, such as the budget or the cooling factor in the simulated annealing method, should have default values
	%\item a budget parameter(B) should be either a maximum number of configurations to run or maximum alloted time. These should be represented by the keys \textbf{max\_iter} and \textbf{max\_time} in the configuration file.
	%\item tuning a SLAM algorithm's parameters is classified as a test, for easier integration in the existing RUSTLE's architecture.
	%\item when running a tuning test, all tested parameter combinations should have their respective metrics stored together, for later processing
	%\item when running a tuning test, all tuning settings should be stored as well, for later processing and examination
	%\item for overall testing and comparison of different tuning strategies, there should be a command to run a set of tuning algorithms and produce appropriate metrics which later could be displayed as a table or graph.
	%\item The tuning module should run different configurations concurrently, when possible.
%\end{itemize}

\section{Testing}

\subsection{Metrics}

%\paragraph{}Write something about evalutation functions to compare configurations and obtain the better one.
%\paragraph{}Probably not worth writing an entire subsection about this, but mention that only the RPE is being considered and why, but also mention that the code allows, with a few modifications to consider other metrics(like memory usage and CPU time) into the fitness function, with various weigth distributions.
\paragraph{}During the development, as well as during testing stages, only the \ac{RPE} is begin considered. However, the user can attribute weights to both the \ac{APE} and \ac{RPE} using a YAML configuration file. However, the code supports, with a few smal moddifications, taking into account other metrics(CPU load, memory usage, etc) when computing the fitness value of a configuration.

\subsection{Algorithms}

\paragraph{}In this subsection, I explain both the \ac{SLAM} methods I chose to optimize and the hyperparameters I chose to optimize and why.

\paragraph{}One thing that is applicable to both \ac{SLAM} solutions chosen is that due to the high number of hyperparameters and the memory constraints, it is not possible  neither to optimize every hyperparameter nor to give every hyperparameter a very large number of possible values. For that reason, only a select few hyperparameters will be optimized, and the choices of hyperparameters will be fully explained below.

\subsubsection{faster-lio}

\subsubsection{fast-livo2}

%\paragraph{}Write something about the algorithms tested(point-lio, ig-lio, etc), but emphasize the tuning algorithms apply to any SLAM method.
\paragraph{}Write something about faster-lio and fast-livo2 and why they were chosen.

\subsection{Dataset}

%\paragraph{}Mention the datasets used during development, but stress that, as in the SLAM methods used, the tuning algorithms generalize to any dataset.
\paragraph{}Something about the 2.5 minute Botanic Garden Dataset(outdoor, unstructured setting, not too long(for tuning experiments)).